{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "from model import *\n",
    "from train import test\n",
    "import torch.optim as optim\n",
    "\n",
    "from MatrixVectorizer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csvs as numpy\n",
    "lr_data_path = '../data/lr_train.csv'\n",
    "hr_data_path = '../data/hr_train.csv'\n",
    "\n",
    "lr_train_data = np.loadtxt(lr_data_path, delimiter=',')\n",
    "hr_train_data = np.loadtxt(hr_data_path, delimiter=',')\n",
    "lr_train_data[lr_train_data < 0] = 0\n",
    "np.nan_to_num(lr_train_data, copy=False)\n",
    "\n",
    "hr_train_data[hr_train_data < 0] = 0\n",
    "np.nan_to_num(hr_train_data, copy=False)\n",
    "\n",
    "\n",
    "\n",
    "# map the anti-vectorize function to each row of the lr_train_data\n",
    "\n",
    "lr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 160) for row in lr_train_data])\n",
    "hr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 268) for row in hr_train_data])\n",
    "num_samples = hr_train_data_vectorized.shape[0]\n",
    "split = int(num_samples * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects_adj,subjects_labels = lr_train_data_vectorized[:split], hr_train_data_vectorized[:split]\n",
    "\n",
    "held_out_subjects_adj,held_out_subjects_labels = lr_train_data_vectorized[split:], hr_train_data_vectorized[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splt = 3\n",
    "epochs = 100\n",
    "# lr = 0.001\n",
    "lr = 0.0001\n",
    "lmbda = 16\n",
    "lr_dim = 160\n",
    "hr_dim = 320\n",
    "hidden_dim = 320\n",
    "padding = 26\n",
    "dropout = 0\n",
    "args = argparse.Namespace()\n",
    "args.epochs = epochs\n",
    "args.lr = lr\n",
    "args.lmbda = lmbda\n",
    "args.lr_dim = lr_dim\n",
    "args.hr_dim = hr_dim\n",
    "args.hidden_dim = hidden_dim\n",
    "args.padding = padding\n",
    "args.p = dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks = [0]\n",
    "ks = [0.9, 0.7, 0.6, 0.5]\n",
    "model = GSRNet(ks, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "def train(model, optimizer, subjects_adj,subjects_labels, args): \n",
    "  #, subjects_adj_test, subjects_ground_truth_test):\n",
    "  \n",
    "  all_epochs_loss = []\n",
    "  no_epochs = args.epochs\n",
    "\n",
    "  for epoch in range(no_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_error = []\n",
    "\n",
    "    model.train()\n",
    "    for lr,hr in zip(subjects_adj,subjects_labels):      \n",
    "      lr = torch.from_numpy(lr).type(torch.FloatTensor)\n",
    "      hr = torch.from_numpy(hr).type(torch.FloatTensor)\n",
    "      \n",
    "      \n",
    "      # net_outs,start_gcn_outs,layer_outs = model(lr)\n",
    "      model_outputs,net_outs,start_gcn_outs,layer_outs = model(lr)\n",
    "      model_outputs  = unpad(model_outputs, args.padding)\n",
    "      # weights = unpad(model.layer.weights, args.padding)\n",
    "      \n",
    "\n",
    "      padded_hr = pad_HR_adj(hr,args.padding)\n",
    "      eig_val_hr, U_hr = torch.linalg.eigh(padded_hr, UPLO='U')\n",
    "\n",
    "      # print the shapes of the outputs\n",
    "      # print(f\"{net_outs.shape} ; {start_gcn_outs.shape}\")\n",
    "      # print(f\"{model.layer.weights.shape} ; {U_hr.shape}\")\n",
    "      # print(f\"{model_outputs.shape} ; {hr.shape}\")\n",
    "      \n",
    "      # loss = criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + args.lmbda * criterion(model_outputs, hr) \n",
    "      # loss = criterion(model_outputs, hr) \n",
    "      loss = args.lmbda * criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + criterion(model_outputs, hr) \n",
    "\n",
    "      \n",
    "      error = criterion(model_outputs, hr)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss.append(loss.item())\n",
    "      epoch_error.append(error.item())\n",
    "      \n",
    "  \n",
    "    model.eval()\n",
    "    print(\"Epoch: \",epoch+1, \"Loss: \", np.mean(epoch_loss), \"Error: \", np.mean(epoch_error))\n",
    "    test(model, held_out_subjects_adj, held_out_subjects_labels, args)\n",
    "    # test(model, subjects_adj_test, subjects_ground_truth_test, args)\n",
    "    all_epochs_loss.append(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  133.43583360870383 Error:  133.23096602843768\n",
      "Test error MAE:  0.2053389895488234\n",
      "Epoch:  2 Loss:  133.3243507255814 Error:  133.19718935996738\n",
      "Test error MAE:  0.18793600096422083\n",
      "Epoch:  3 Loss:  133.30533874190564 Error:  133.18615737435087\n",
      "Test error MAE:  0.18137606846935608\n",
      "Epoch:  4 Loss:  133.29338433426707 Error:  133.18141211847316\n",
      "Test error MAE:  0.1783861311919549\n",
      "Epoch:  5 Loss:  133.28463975195564 Error:  133.17893316596746\n",
      "Test error MAE:  0.1760371060055845\n",
      "Epoch:  6 Loss:  133.27675985756204 Error:  133.1766870439942\n",
      "Test error MAE:  0.1740377343752805\n",
      "Epoch:  7 Loss:  133.27064004140115 Error:  133.17522112502536\n",
      "Test error MAE:  0.17261631304726882\n",
      "Epoch:  8 Loss:  133.2656074667822 Error:  133.17425134044086\n",
      "Test error MAE:  0.17185837205718546\n",
      "Epoch:  9 Loss:  133.26182974619206 Error:  133.17378065846304\n",
      "Test error MAE:  0.17136224666062524\n",
      "Epoch:  10 Loss:  133.25861136303908 Error:  133.1733523858572\n",
      "Test error MAE:  0.1710091141216895\n",
      "Epoch:  11 Loss:  133.25601251634643 Error:  133.17311398707218\n",
      "Test error MAE:  0.17073111542884042\n",
      "Epoch:  12 Loss:  133.25377034429295 Error:  133.17291072567008\n",
      "Test error MAE:  0.17045989501125672\n",
      "Epoch:  13 Loss:  133.25189798013932 Error:  133.1728105668479\n",
      "Test error MAE:  0.170340998646091\n",
      "Epoch:  14 Loss:  133.25012884322388 Error:  133.17263321611864\n",
      "Test error MAE:  0.1701847867054098\n",
      "Epoch:  15 Loss:  133.2486034662866 Error:  133.17246796402023\n",
      "Test error MAE:  0.17007934345918543\n",
      "Epoch:  16 Loss:  133.2471731702116 Error:  133.17237585471636\n",
      "Test error MAE:  0.16993168084060445\n",
      "Epoch:  17 Loss:  133.24592225798474 Error:  133.17239119635144\n",
      "Test error MAE:  0.16988071930759094\n",
      "Epoch:  18 Loss:  133.24458123198642 Error:  133.17223249131175\n",
      "Test error MAE:  0.16984505600789013\n",
      "Epoch:  19 Loss:  133.24345875197827 Error:  133.17222535343313\n",
      "Test error MAE:  0.16979039723382278\n",
      "Epoch:  20 Loss:  133.24241646957486 Error:  133.17210860539282\n",
      "Test error MAE:  0.16975193120100918\n",
      "Epoch:  21 Loss:  133.24124670695903 Error:  133.17206123115412\n",
      "Test error MAE:  0.1697129686089123\n",
      "Epoch:  22 Loss:  133.24020340627254 Error:  133.1720116495419\n",
      "Test error MAE:  0.16966885284465902\n",
      "Epoch:  23 Loss:  133.23927330236828 Error:  133.1719243693263\n",
      "Test error MAE:  0.16965596903772914\n",
      "Epoch:  24 Loss:  133.2384162495163 Error:  133.1719479269501\n",
      "Test error MAE:  0.16957205709289103\n",
      "Epoch:  25 Loss:  133.2374299714592 Error:  133.171907153481\n",
      "Test error MAE:  0.1695851091952885\n",
      "Epoch:  26 Loss:  133.2365522605937 Error:  133.1718821245343\n",
      "Test error MAE:  0.16960743025821798\n",
      "Epoch:  27 Loss:  133.23565045888745 Error:  133.17178134486747\n",
      "Test error MAE:  0.16959739870884838\n",
      "Epoch:  28 Loss:  133.23485669938486 Error:  133.1717564700477\n",
      "Test error MAE:  0.16956111218999415\n",
      "Epoch:  29 Loss:  133.2340775410186 Error:  133.17186530256893\n",
      "Test error MAE:  0.16958781638566187\n",
      "Epoch:  30 Loss:  133.233267840832 Error:  133.1717415562094\n",
      "Test error MAE:  0.169574053848491\n",
      "Epoch:  31 Loss:  133.23257565253707 Error:  133.17173478774615\n",
      "Test error MAE:  0.16954511491691365\n",
      "Epoch:  32 Loss:  133.23193059138842 Error:  133.17161377018957\n",
      "Test error MAE:  0.16955222846830592\n",
      "Epoch:  33 Loss:  133.23128454331587 Error:  133.17173007197346\n",
      "Test error MAE:  0.16960974870359197\n",
      "Epoch:  34 Loss:  133.2305307153668 Error:  133.17155133310095\n",
      "Test error MAE:  0.16958553869934642\n",
      "Epoch:  35 Loss:  133.2298038998869 Error:  133.1716116221983\n",
      "Test error MAE:  0.1695503311998704\n",
      "Epoch:  36 Loss:  133.2290936275872 Error:  133.17158574310702\n",
      "Test error MAE:  0.16954768799683628\n",
      "Epoch:  37 Loss:  133.22847404164165 Error:  133.1715035199452\n",
      "Test error MAE:  0.1695245350984966\n",
      "Epoch:  38 Loss:  133.2279407039507 Error:  133.1715545865582\n",
      "Test error MAE:  0.1695612024735002\n",
      "Epoch:  39 Loss:  133.2271750541543 Error:  133.17144711415713\n",
      "Test error MAE:  0.16954765600316665\n",
      "Epoch:  40 Loss:  133.22667883381024 Error:  133.17143809962184\n",
      "Test error MAE:  0.16953708757372463\n",
      "Epoch:  41 Loss:  133.22616785353244 Error:  133.17154746013347\n",
      "Test error MAE:  0.16953082645640655\n"
     ]
    }
   ],
   "source": [
    "# print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "train(model, optimizer, subjects_adj, subjects_labels, args)\n",
    "\n",
    "print('Held out test score:')\n",
    "test(model, held_out_subjects_adj, held_out_subjects_labels, args)\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(model)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# # optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "# for train_index, test_index in cv.split(subjects_adj):\n",
    "#     subjects_adj_train = subjects_adj[train_index]  # Get training data \n",
    "#     subjects_adj_test = subjects_adj[test_index]   # Get testing data \n",
    "#     subjects_ground_truth_train = subjects_labels[train_index]\n",
    "#     subjects_ground_truth_test = subjects_labels[test_index]\n",
    "\n",
    "#     train(model, optimizer, subjects_adj_train, subjects_ground_truth_train, args, subjects_adj_test, subjects_ground_truth_test)\n",
    "    \n",
    "#     print('Held out test score:')\n",
    "#     test(model, held_out_subjects_adj, held_out_subjects_labels, args)\n",
    "#     print('------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
