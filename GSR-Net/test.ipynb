{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "from model import *\n",
    "from train import test\n",
    "import torch.optim as optim\n",
    "\n",
    "from MatrixVectorizer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csvs as numpy\n",
    "lr_data_path = '../data/lr_train.csv'\n",
    "hr_data_path = '../data/hr_train.csv'\n",
    "\n",
    "lr_train_data = np.loadtxt(lr_data_path, delimiter=',')\n",
    "hr_train_data = np.loadtxt(hr_data_path, delimiter=',')\n",
    "lr_train_data[lr_train_data < 0] = 0\n",
    "np.nan_to_num(lr_train_data, copy=False)\n",
    "\n",
    "hr_train_data[hr_train_data < 0] = 0\n",
    "np.nan_to_num(hr_train_data, copy=False)\n",
    "\n",
    "# map the anti-vectorize function to each row of the lr_train_data\n",
    "\n",
    "lr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 160) for row in lr_train_data])\n",
    "hr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 260) for row in hr_train_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects_adj,subjects_labels = lr_train_data_vectorized, hr_train_data_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splt = 3\n",
    "epochs = 10\n",
    "lr = 0.00005\n",
    "lmbda = 5000\n",
    "lr_dim = 160\n",
    "hr_dim = 320\n",
    "hidden_dim = 512\n",
    "padding = 30\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.epochs = epochs\n",
    "args.lr = lr\n",
    "args.lmbda = lmbda\n",
    "args.lr_dim = lr_dim\n",
    "args.hr_dim = hr_dim\n",
    "args.hidden_dim = hidden_dim\n",
    "args.padding = padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks = [0]\n",
    "ks = [0.7, 0.3]\n",
    "model = GSRNet(ks, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "def train(model, optimizer, subjects_adj,subjects_labels, args):\n",
    "  \n",
    "  all_epochs_loss = []\n",
    "  no_epochs = args.epochs\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(no_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_error = []\n",
    "\n",
    "    for lr,hr in zip(subjects_adj,subjects_labels):      \n",
    "      lr = torch.from_numpy(lr).type(torch.FloatTensor)\n",
    "      hr = torch.from_numpy(hr).type(torch.FloatTensor)\n",
    "      \n",
    "      model_outputs,net_outs,start_gcn_outs,layer_outs = model(lr)\n",
    "      # model_outputs  = unpad(model_outputs, args.padding)\n",
    "      # weights = unpad(model.layer.weights, args.padding)\n",
    "      \n",
    "\n",
    "      padded_hr = pad_HR_adj(hr,args.padding)\n",
    "      eig_val_hr, U_hr = torch.linalg.eigh(padded_hr, UPLO='U')\n",
    "\n",
    "      # print the shapes of the outputs\n",
    "      # print(f\"{net_outs.shape} ; {start_gcn_outs.shape}\")\n",
    "      # print(f\"{weights.shape} ; {U_hr.shape}\")\n",
    "      # print(f\"{model_outputs.shape} ; {hr.shape}\")\n",
    "      \n",
    "      # loss = criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + args.lmbda * criterion(model_outputs, hr) \n",
    "      # loss = criterion(model_outputs, hr) \n",
    "      loss = args.lmbda * criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + criterion(model_outputs, padded_hr) \n",
    "\n",
    "      \n",
    "      error = criterion(model_outputs, padded_hr)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss.append(loss.item())\n",
    "      epoch_error.append(error.item())\n",
    "      \n",
    "    print(\"Epoch: \",epoch+1, \"Loss: \", np.mean(epoch_loss), \"Error: \", np.mean(epoch_error))\n",
    "    all_epochs_loss.append(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  167.78789940902166 Error:  99.00568245777062\n",
      "Epoch:  2 Loss:  120.86639038154057 Error:  98.9898308051883\n",
      "Epoch:  3 Loss:  119.41274318524769 Error:  98.98385526585791\n",
      "Epoch:  4 Loss:  118.14172511441367 Error:  98.98142526085887\n",
      "Epoch:  5 Loss:  116.99101482970374 Error:  98.98006225696632\n",
      "Epoch:  6 Loss:  115.92167899438313 Error:  98.97875495627522\n",
      "Epoch:  7 Loss:  114.92061139856067 Error:  98.97756719150182\n",
      "Epoch:  8 Loss:  113.98398394244057 Error:  98.97731903208685\n",
      "Epoch:  9 Loss:  113.10207540648324 Error:  98.97681726482031\n",
      "Epoch:  10 Loss:  112.2802266393389 Error:  98.97660394618288\n",
      "0.2599385976791382\n",
      "0.20166757702827454\n",
      "0.17209911346435547\n",
      "0.16911724209785461\n",
      "0.18098625540733337\n",
      "0.16789790987968445\n",
      "0.20097719132900238\n",
      "0.1802479773759842\n",
      "0.22633971273899078\n",
      "0.1820221245288849\n",
      "0.20679205656051636\n",
      "0.16337832808494568\n",
      "0.15906211733818054\n",
      "0.2293432205915451\n",
      "0.38961100578308105\n",
      "0.1844160109758377\n",
      "0.18851490318775177\n",
      "0.1682729721069336\n",
      "0.17128974199295044\n",
      "0.17049472033977509\n",
      "0.1772257387638092\n",
      "0.17448532581329346\n",
      "0.18159762024879456\n",
      "0.17828291654586792\n",
      "0.18697196245193481\n",
      "0.1742696762084961\n",
      "0.18949811160564423\n",
      "0.17666111886501312\n",
      "0.17709678411483765\n",
      "0.17170244455337524\n",
      "0.18179462850093842\n",
      "0.17887172102928162\n",
      "0.16859856247901917\n",
      "0.18755920231342316\n",
      "0.169114887714386\n",
      "0.19297535717487335\n",
      "0.15698349475860596\n",
      "0.1817987561225891\n",
      "0.22193370759487152\n",
      "0.16491785645484924\n",
      "0.15980017185211182\n",
      "0.176802858710289\n",
      "0.20947296917438507\n",
      "0.17598898708820343\n",
      "0.1927412748336792\n",
      "0.17066636681556702\n",
      "0.16841326653957367\n",
      "0.17835131287574768\n",
      "0.17439155280590057\n",
      "0.17383432388305664\n",
      "0.1971139758825302\n",
      "0.18514972925186157\n",
      "0.1776781529188156\n",
      "0.1649533212184906\n",
      "0.1786801964044571\n",
      "0.17377415299415588\n",
      "Test error MAE:  0.1861182368759598\n",
      "Epoch:  1 Loss:  12.737639376095363 Error:  0.1303768372828407\n",
      "Epoch:  2 Loss:  12.036265002829689 Error:  0.13018889598814504\n",
      "Epoch:  3 Loss:  11.392940827778407 Error:  0.13005424916212047\n",
      "Epoch:  4 Loss:  10.798682161739894 Error:  0.13003414922526904\n",
      "Epoch:  5 Loss:  10.254040075199944 Error:  0.1298403906236802\n",
      "Epoch:  6 Loss:  9.75062684927668 Error:  0.1297086961567402\n",
      "Epoch:  7 Loss:  9.291737479822975 Error:  0.12933755054005555\n",
      "Epoch:  8 Loss:  8.879318326711655 Error:  0.12924592369901283\n",
      "Epoch:  9 Loss:  8.510075258357185 Error:  0.1293212388242994\n",
      "Epoch:  10 Loss:  8.180247868810381 Error:  0.1292856261799378\n",
      "16769.58984375\n",
      "0.17880162596702576\n",
      "0.17707139253616333\n",
      "0.19137521088123322\n",
      "0.21944096684455872\n",
      "0.19331209361553192\n",
      "0.15650999546051025\n",
      "0.16497018933296204\n",
      "0.2163798063993454\n",
      "0.29086995124816895\n",
      "0.17421604692935944\n",
      "0.17353951930999756\n",
      "0.19930410385131836\n",
      "0.29334133863449097\n",
      "0.22936712205410004\n",
      "0.1677050143480301\n",
      "0.23501187562942505\n",
      "0.1764334738254547\n",
      "0.173622265458107\n",
      "0.17452871799468994\n",
      "0.1723848432302475\n",
      "0.20391157269477844\n",
      "0.1707577109336853\n",
      "0.17656923830509186\n",
      "0.1616130918264389\n",
      "0.1723625659942627\n",
      "0.16893811523914337\n",
      "0.20753824710845947\n",
      "0.19917573034763336\n",
      "0.18517965078353882\n",
      "0.18449018895626068\n",
      "0.17675134539604187\n",
      "0.19576555490493774\n",
      "0.1627647429704666\n",
      "0.1595836579799652\n",
      "0.17162123322486877\n",
      "0.17672759294509888\n",
      "0.21807053685188293\n",
      "0.23407389223575592\n",
      "0.24198444187641144\n",
      "0.25546377897262573\n",
      "0.16844047605991364\n",
      "0.21670089662075043\n",
      "0.1777316927909851\n",
      "0.18015000224113464\n",
      "0.17611020803451538\n",
      "0.26067915558815\n",
      "0.17839179933071136\n",
      "0.16026164591312408\n",
      "0.19702111184597015\n",
      "0.19798682630062103\n",
      "0.16082467138767242\n",
      "0.24205365777015686\n",
      "0.22358936071395874\n",
      "0.19745148718357086\n",
      "0.2021644562482834\n",
      "Test error MAE:  299.6484094578773\n",
      "Epoch:  1 Loss:  106.77742201089859 Error:  98.97511973997045\n",
      "Epoch:  2 Loss:  106.48391365579197 Error:  98.97543178591877\n",
      "Epoch:  3 Loss:  106.23259650383677 Error:  98.9746909983057\n",
      "Epoch:  4 Loss:  106.01077395251819 Error:  98.97480139109705\n",
      "Epoch:  5 Loss:  105.80738584910121 Error:  98.97429702211437\n",
      "Epoch:  6 Loss:  105.62191325851849 Error:  98.9741182776301\n",
      "Epoch:  7 Loss:  105.45048541682107 Error:  98.97440714568698\n",
      "Epoch:  8 Loss:  105.28961632507188 Error:  98.97402044079665\n",
      "Epoch:  9 Loss:  105.13489139080048 Error:  98.9738471120862\n",
      "Epoch:  10 Loss:  104.98733921136174 Error:  98.9735841371252\n",
      "0.17384159564971924\n",
      "0.17630183696746826\n",
      "0.18142107129096985\n",
      "0.19220972061157227\n",
      "0.17449428141117096\n",
      "0.23901887238025665\n",
      "0.17766360938549042\n",
      "0.17718325555324554\n",
      "0.1799314171075821\n",
      "0.18053777515888214\n",
      "0.24441464245319366\n",
      "0.16778478026390076\n",
      "0.1664532870054245\n",
      "0.16243989765644073\n",
      "0.17806290090084076\n",
      "0.1659952849149704\n",
      "0.18313153088092804\n",
      "0.18118101358413696\n",
      "0.19009187817573547\n",
      "0.17249450087547302\n",
      "0.16593706607818604\n",
      "0.18647411465644836\n",
      "0.33607134222984314\n",
      "0.1839665025472641\n",
      "0.20786355435848236\n",
      "0.17037490010261536\n",
      "0.1934739053249359\n",
      "0.18309012055397034\n",
      "0.18244460225105286\n",
      "0.16137844324111938\n",
      "0.16053274273872375\n",
      "0.19596898555755615\n",
      "0.202479749917984\n",
      "0.2033693939447403\n",
      "0.16382746398448944\n",
      "0.1670323759317398\n",
      "0.17728471755981445\n",
      "0.18541991710662842\n",
      "0.16915477812290192\n",
      "0.18512128293514252\n",
      "0.19253918528556824\n",
      "0.1796632707118988\n",
      "0.2327902764081955\n",
      "0.19470076262950897\n",
      "0.20269358158111572\n",
      "0.18594318628311157\n",
      "0.1707226186990738\n",
      "0.16492176055908203\n",
      "0.1848677098751068\n",
      "0.16993533074855804\n",
      "0.17739363014698029\n",
      "0.180729940533638\n",
      "0.1744236797094345\n",
      "0.18556904792785645\n",
      "0.17714083194732666\n",
      "0.1718917042016983\n",
      "Test error MAE:  0.18556867193962848\n"
     ]
    }
   ],
   "source": [
    "# print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "for train_index, test_index in cv.split(subjects_adj):\n",
    "    subjects_adj_train = subjects_adj[train_index]  # Get training data \n",
    "    subjects_adj_test = subjects_adj[test_index]   # Get testing data \n",
    "    subjects_ground_truth_train = subjects_labels[train_index]\n",
    "    subjects_ground_truth_test = subjects_labels[test_index]\n",
    "\n",
    "    train(model, optimizer, subjects_adj_train, subjects_ground_truth_train, args)\n",
    "    test(model, subjects_adj_test, subjects_ground_truth_test, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
