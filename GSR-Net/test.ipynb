{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from sklearn.model_selection import train_test_split, KFold, ParameterGrid\n",
    "import argparse\n",
    "from model import *\n",
    "from train import test\n",
    "import torch.optim as optim\n",
    "\n",
    "from MatrixVectorizer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csvs as numpy\n",
    "lr_data_path = '../data/lr_train.csv'\n",
    "hr_data_path = '../data/hr_train.csv'\n",
    "\n",
    "lr_train_data = np.loadtxt(lr_data_path, delimiter=',')\n",
    "hr_train_data = np.loadtxt(hr_data_path, delimiter=',')\n",
    "lr_train_data[lr_train_data < 0] = 0\n",
    "np.nan_to_num(lr_train_data, copy=False)\n",
    "\n",
    "hr_train_data[hr_train_data < 0] = 0\n",
    "np.nan_to_num(hr_train_data, copy=False)\n",
    "\n",
    "# map the anti-vectorize function to each row of the lr_train_data\n",
    "\n",
    "lr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 160) for row in lr_train_data])\n",
    "hr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 260) for row in hr_train_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lr_train into test and training set (training set passed to kfold for cross validation)\n",
    "test_proportion = 0.2\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_train_data_vectorized, hr_train_data_vectorized, test_size=test_proportion, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_train_data_vectorized.shape=(168, 160, 160)\n",
      "lr_train.shape=(134, 160, 160)\n",
      "lr_test.shape=(34, 160, 160)\n",
      "hr_train_data_vectorized.shape=(168, 260, 260)\n",
      "hr_train.shape=(134, 260, 260)\n",
      "hr_test.shape=(34, 260, 260)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{lr_train_data_vectorized.shape=}\")\n",
    "print(f\"{lr_train.shape=}\")\n",
    "print(f\"{lr_test.shape=}\")\n",
    "\n",
    "print(f\"{hr_train_data_vectorized.shape=}\")\n",
    "print(f\"{hr_train.shape=}\")\n",
    "print(f\"{hr_test.shape=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "def train(model, optimizer, lr_train, hr_train, args):\n",
    "  \n",
    "  all_epochs_loss = []\n",
    "  no_epochs = args.epochs\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(no_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_error = []\n",
    "\n",
    "    for lr,hr in zip(lr_train, hr_train):      \n",
    "      lr = torch.from_numpy(lr).type(torch.FloatTensor)\n",
    "      hr = torch.from_numpy(hr).type(torch.FloatTensor)\n",
    "      \n",
    "      model_outputs,net_outs,start_gcn_outs,layer_outs = model(lr)\n",
    "      # model_outputs  = unpad(model_outputs, args.padding)\n",
    "      # weights = unpad(model.layer.weights, args.padding)\n",
    "      \n",
    "      padded_hr = pad_HR_adj(hr,args.padding)\n",
    "      eig_val_hr, U_hr = torch.linalg.eigh(padded_hr, UPLO='U')\n",
    "      \n",
    "      # loss = criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + args.lmbda * criterion(model_outputs, hr) \n",
    "      loss = args.lmbda * criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + criterion(model_outputs, padded_hr) \n",
    "\n",
    "      \n",
    "      error = criterion(model_outputs, padded_hr)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss.append(loss.item())\n",
    "      epoch_error.append(error.item())\n",
    "      \n",
    "    print(\"Epoch: \",epoch+1, \"Loss: \", np.mean(epoch_loss), \"Error: \", np.mean(epoch_error))\n",
    "    all_epochs_loss.append(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparams: {'hidden_dim': 256, 'lmbda': 1000, 'lr': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  135.62602110123368 Error:  124.54854009811127\n",
      "Epoch:  2 Loss:  129.06227593743398 Error:  124.53123877272847\n",
      "Epoch:  3 Loss:  128.63830950554836 Error:  124.52418454250927\n",
      "Epoch:  4 Loss:  128.25831981991115 Error:  124.52103321664454\n",
      "Epoch:  5 Loss:  127.91880815484551 Error:  124.51928923965505\n",
      "Epoch:  6 Loss:  127.61912836921348 Error:  124.51848003301728\n",
      "Epoch:  7 Loss:  127.3566579657994 Error:  124.51769013627526\n",
      "Epoch:  8 Loss:  127.13027440831902 Error:  124.51748274342063\n",
      "Epoch:  9 Loss:  126.93418893653356 Error:  124.51687634133556\n",
      "Epoch:  10 Loss:  126.76505933718735 Error:  124.51635145270423\n",
      "Test error MAE:  0.18867355518870885\n",
      "Epoch:  1 Loss:  126.63289821951577 Error:  124.51638979858227\n",
      "Epoch:  2 Loss:  126.49974152211392 Error:  124.51635146559624\n",
      "Epoch:  3 Loss:  126.38148059603873 Error:  124.51571641150821\n",
      "Epoch:  4 Loss:  126.27705239312033 Error:  124.51558829107312\n",
      "Epoch:  5 Loss:  126.18570566445254 Error:  124.51601550292767\n",
      "Epoch:  6 Loss:  126.10221194953061 Error:  124.51583290820041\n",
      "Epoch:  7 Loss:  126.02542845988542 Error:  124.5155170174797\n",
      "Epoch:  8 Loss:  125.9566905029704 Error:  124.51524492395058\n",
      "Epoch:  9 Loss:  125.89557019914135 Error:  124.51516017861915\n",
      "Epoch:  10 Loss:  125.8393417462874 Error:  124.51530987526594\n",
      "Test error MAE:  0.18676247596740722\n",
      "Epoch:  1 Loss:  1.4389475815825992 Error:  0.12903625385628806\n",
      "Epoch:  2 Loss:  1.3873146030637953 Error:  0.12895377377669018\n",
      "Epoch:  3 Loss:  1.3391020834445952 Error:  0.12932407218548986\n",
      "Epoch:  4 Loss:  1.2943423986434937 Error:  0.12895662511388462\n",
      "Epoch:  5 Loss:  1.252647692627377 Error:  0.12876962597171465\n",
      "Epoch:  6 Loss:  1.2121906790468429 Error:  0.12887920348180665\n",
      "Epoch:  7 Loss:  1.1748760766453212 Error:  0.129201925959852\n",
      "Epoch:  8 Loss:  1.1380793783399794 Error:  0.12929007295105194\n",
      "Epoch:  9 Loss:  1.1022895667288037 Error:  0.12905997153785492\n",
      "Epoch:  10 Loss:  1.0687640945116679 Error:  0.12930504489276146\n",
      "Test error MAE:  381.3072500012138\n",
      "[0.18867355518870885, 0.18676247596740722, 381.3072500012138]\n",
      "Validation loss: 127.22756201078998\n",
      "Training with hyperparams: {'hidden_dim': 256, 'lmbda': 1000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  133.13782440946343 Error:  124.5425734436244\n",
      "Epoch:  2 Loss:  128.5484231054113 Error:  124.52515768335107\n",
      "Epoch:  3 Loss:  127.96605715590917 Error:  124.52223677506272\n",
      "Epoch:  4 Loss:  127.49354351236579 Error:  124.52107295804144\n",
      "Epoch:  5 Loss:  127.12105876676152 Error:  124.52072611484635\n",
      "Epoch:  6 Loss:  126.81753920437245 Error:  124.52045254266999\n",
      "Epoch:  7 Loss:  126.57381262136309 Error:  124.52064671400893\n",
      "Epoch:  8 Loss:  126.37463384799743 Error:  124.52061022684146\n",
      "Epoch:  9 Loss:  126.21106439494015 Error:  124.52153217306967\n",
      "Epoch:  10 Loss:  126.06861298137837 Error:  124.52159380335152\n",
      "Test error MAE:  0.19383186499277752\n",
      "Epoch:  1 Loss:  125.98139435253786 Error:  124.5221862567777\n",
      "Epoch:  2 Loss:  125.87405418813898 Error:  124.52231373771858\n",
      "Epoch:  3 Loss:  125.78994328520271 Error:  124.5221406682656\n",
      "Epoch:  4 Loss:  125.71760842773352 Error:  124.52243604753794\n",
      "Epoch:  5 Loss:  125.65343597296918 Error:  124.52219949930571\n",
      "Epoch:  6 Loss:  125.59127497740006 Error:  124.52188972199566\n",
      "Epoch:  7 Loss:  125.53212121162522 Error:  124.5213987501652\n",
      "Epoch:  8 Loss:  125.47652374961403 Error:  124.52120184797919\n",
      "Epoch:  9 Loss:  125.4282573923636 Error:  124.52097544676802\n",
      "Epoch:  10 Loss:  125.37685649381595 Error:  124.52099944885528\n",
      "Test error MAE:  0.19118062688244714\n",
      "Epoch:  1 Loss:  0.973610891898473 Error:  0.13471924463907878\n",
      "Epoch:  2 Loss:  0.9208866304821438 Error:  0.13431021405590904\n",
      "Epoch:  3 Loss:  0.8726310511430104 Error:  0.13422372043132783\n",
      "Epoch:  4 Loss:  0.8259408414363861 Error:  0.13409852981567383\n",
      "Epoch:  5 Loss:  0.7809819334083133 Error:  0.1337087238828341\n",
      "Epoch:  6 Loss:  0.7394476936923133 Error:  0.13371949278646045\n",
      "Epoch:  7 Loss:  0.7024229480160608 Error:  0.1336652883225017\n",
      "Epoch:  8 Loss:  0.6641103943188985 Error:  0.13366675443119472\n",
      "Epoch:  9 Loss:  0.6331682509846157 Error:  0.13330813555253876\n",
      "Epoch:  10 Loss:  0.6102850006686317 Error:  0.13389651626348495\n",
      "Test error MAE:  381.3122834874825\n",
      "[0.19383186499277752, 0.19118062688244714, 381.3122834874825]\n",
      "Validation loss: 127.23243199311923\n",
      "Training with hyperparams: {'hidden_dim': 256, 'lmbda': 5000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  178.95765555306767 Error:  124.54865059633268\n",
      "Epoch:  2 Loss:  146.12500004286176 Error:  124.53121497833662\n",
      "Epoch:  3 Loss:  144.1966633850269 Error:  124.5250134709176\n",
      "Epoch:  4 Loss:  142.5525730433089 Error:  124.52194140893354\n",
      "Epoch:  5 Loss:  141.09114396170284 Error:  124.52064697343981\n",
      "Epoch:  6 Loss:  139.76317791456586 Error:  124.51965804557118\n",
      "Epoch:  7 Loss:  138.54365117362377 Error:  124.5191927033194\n",
      "Epoch:  8 Loss:  137.42315486307893 Error:  124.51939645175183\n",
      "Epoch:  9 Loss:  136.39592181966546 Error:  124.5192481621765\n",
      "Epoch:  10 Loss:  135.46393425544997 Error:  124.5190015092827\n",
      "Test error MAE:  0.19203620354334514\n",
      "Epoch:  1 Loss:  134.67102010062573 Error:  124.51877397014184\n",
      "Epoch:  2 Loss:  133.91476137182687 Error:  124.51905466113867\n",
      "Epoch:  3 Loss:  133.2785822621892 Error:  124.51836556263184\n",
      "Epoch:  4 Loss:  132.7451421330484 Error:  124.51858671511827\n",
      "Epoch:  5 Loss:  132.29002121593174 Error:  124.51846102650246\n",
      "Epoch:  6 Loss:  131.9076232106498 Error:  124.51874674119976\n",
      "Epoch:  7 Loss:  131.5727455107014 Error:  124.51894459706008\n",
      "Epoch:  8 Loss:  131.28730613729928 Error:  124.51920937964421\n",
      "Epoch:  9 Loss:  131.03109108464102 Error:  124.51912590777606\n",
      "Epoch:  10 Loss:  130.79804699608448 Error:  124.51922550705376\n",
      "Test error MAE:  0.19105004767576853\n",
      "Epoch:  1 Loss:  6.381765254338583 Error:  0.13327579374114673\n",
      "Epoch:  2 Loss:  6.150854007403056 Error:  0.13289701532986428\n",
      "Epoch:  3 Loss:  5.9418375253677365 Error:  0.1327828910615709\n",
      "Epoch:  4 Loss:  5.742782717280917 Error:  0.13252856805920601\n",
      "Epoch:  5 Loss:  5.554753960503472 Error:  0.13268743082880974\n",
      "Epoch:  6 Loss:  5.371775510576036 Error:  0.13266639759143192\n",
      "Epoch:  7 Loss:  5.1958218998379175 Error:  0.13253798517915938\n",
      "Epoch:  8 Loss:  5.020970066388448 Error:  0.13270164430141448\n",
      "Epoch:  9 Loss:  4.8529987467659845 Error:  0.13268582928511832\n",
      "Epoch:  10 Loss:  4.6869079086515635 Error:  0.1325390660100513\n",
      "Test error MAE:  381.3108637282117\n",
      "[0.19203620354334514, 0.19105004767576853, 381.3108637282117]\n",
      "Validation loss: 127.23131665981028\n",
      "Training with hyperparams: {'hidden_dim': 256, 'lmbda': 5000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  166.40446710050776 Error:  124.54243476320518\n",
      "Epoch:  2 Loss:  144.15357277902325 Error:  124.52556912651222\n",
      "Epoch:  3 Loss:  141.1622976024499 Error:  124.52179128350167\n",
      "Epoch:  4 Loss:  138.7861967086792 Error:  124.52072444608372\n",
      "Epoch:  5 Loss:  136.93369077832511 Error:  124.51976751452416\n",
      "Epoch:  6 Loss:  135.47902137242008 Error:  124.51950945554489\n",
      "Epoch:  7 Loss:  134.34479223744253 Error:  124.51902264909128\n",
      "Epoch:  8 Loss:  133.4093148735132 Error:  124.51868094261108\n",
      "Epoch:  9 Loss:  132.6371313588003 Error:  124.51909739917583\n",
      "Epoch:  10 Loss:  131.99443813388268 Error:  124.51966409870748\n",
      "Test error MAE:  0.19189871384037865\n",
      "Epoch:  1 Loss:  131.5600204896391 Error:  124.52033658166614\n",
      "Epoch:  2 Loss:  131.0397531423676 Error:  124.51997720977563\n",
      "Epoch:  3 Loss:  130.60526154014502 Error:  124.51998049548168\n",
      "Epoch:  4 Loss:  130.2253769220931 Error:  124.51951362862346\n",
      "Epoch:  5 Loss:  129.89233068401893 Error:  124.51993955788987\n",
      "Epoch:  6 Loss:  129.5835001763333 Error:  124.52006900519802\n",
      "Epoch:  7 Loss:  129.29149679119666 Error:  124.52019251121229\n",
      "Epoch:  8 Loss:  129.02416020832706 Error:  124.5206501197614\n",
      "Epoch:  9 Loss:  128.77117726776038 Error:  124.52076014834509\n",
      "Epoch:  10 Loss:  128.52810015303365 Error:  124.5207338932525\n",
      "Test error MAE:  0.18983688155810038\n",
      "Epoch:  1 Loss:  4.032015517022875 Error:  0.1341800010866589\n",
      "Epoch:  2 Loss:  3.7637867344750298 Error:  0.1342966194781992\n",
      "Epoch:  3 Loss:  3.5149731000264484 Error:  0.13402013430992762\n",
      "Epoch:  4 Loss:  3.289793758922153 Error:  0.13378877863287925\n",
      "Epoch:  5 Loss:  3.070214761628045 Error:  0.13408419556087917\n",
      "Epoch:  6 Loss:  2.868195943037669 Error:  0.13436646635333696\n",
      "Epoch:  7 Loss:  2.6882246772448224 Error:  0.1344845445619689\n",
      "Epoch:  8 Loss:  2.5085891909069487 Error:  0.1343527967731158\n",
      "Epoch:  9 Loss:  2.36463836034139 Error:  0.13453740874926248\n",
      "Epoch:  10 Loss:  2.205106524626414 Error:  0.13450777928034466\n",
      "Test error MAE:  381.3131696476855\n",
      "[0.19189871384037865, 0.18983688155810038, 381.3131696476855]\n",
      "Validation loss: 127.231635081028\n",
      "Training with hyperparams: {'hidden_dim': 256, 'lmbda': 10000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  239.87905639476992 Error:  124.54762434172497\n",
      "Epoch:  2 Loss:  169.31095920519883 Error:  124.5327757483118\n",
      "Epoch:  3 Loss:  165.6909412212586 Error:  124.52600298713098\n",
      "Epoch:  4 Loss:  162.4250844676843 Error:  124.52252324168266\n",
      "Epoch:  5 Loss:  159.31303641501438 Error:  124.52117772718493\n",
      "Epoch:  6 Loss:  156.34075807721428 Error:  124.51947263025501\n",
      "Epoch:  7 Loss:  153.55801638056724 Error:  124.51864791410358\n",
      "Epoch:  8 Loss:  151.01101877448264 Error:  124.51851281640904\n",
      "Epoch:  9 Loss:  148.7075531777371 Error:  124.51811903505848\n",
      "Epoch:  10 Loss:  146.67474610617992 Error:  124.51752186139647\n",
      "Test error MAE:  0.1901628570424186\n",
      "Epoch:  1 Loss:  144.9425750903869 Error:  124.51797268832668\n",
      "Epoch:  2 Loss:  143.37882905595757 Error:  124.51777262977335\n",
      "Epoch:  3 Loss:  142.0557648840915 Error:  124.51735625039326\n",
      "Epoch:  4 Loss:  140.94977597440226 Error:  124.51738727628515\n",
      "Epoch:  5 Loss:  140.03313692500083 Error:  124.51780269738663\n",
      "Epoch:  6 Loss:  139.2391019242533 Error:  124.51782855567302\n",
      "Epoch:  7 Loss:  138.58010819252956 Error:  124.51718109846115\n",
      "Epoch:  8 Loss:  137.99808835447504 Error:  124.51738980236684\n",
      "Epoch:  9 Loss:  137.4789165325379 Error:  124.5176612271854\n",
      "Epoch:  10 Loss:  137.00626501876317 Error:  124.51721165647332\n",
      "Test error MAE:  0.18840349515279134\n",
      "Epoch:  1 Loss:  12.523983028199938 Error:  0.1314106110897329\n",
      "Epoch:  2 Loss:  12.064668242136637 Error:  0.13121069272359212\n",
      "Epoch:  3 Loss:  11.64155691464742 Error:  0.13075071970621746\n",
      "Epoch:  4 Loss:  11.241620588302613 Error:  0.13105066807733642\n",
      "Epoch:  5 Loss:  10.857395198610094 Error:  0.1313747720585929\n",
      "Epoch:  6 Loss:  10.487424702114529 Error:  0.13125668159789508\n",
      "Epoch:  7 Loss:  10.126371929380628 Error:  0.13113229895631473\n",
      "Epoch:  8 Loss:  9.777779308954875 Error:  0.13101989461316002\n",
      "Epoch:  9 Loss:  9.435736926396688 Error:  0.13112175207999016\n",
      "Epoch:  10 Loss:  9.104299163818359 Error:  0.13083615940478113\n",
      "Test error MAE:  381.3078350455246\n",
      "[0.1901628570424186, 0.18840349515279134, 381.3078350455246]\n",
      "Validation loss: 127.2288004659066\n",
      "Training with hyperparams: {'hidden_dim': 256, 'lmbda': 10000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  209.45742326372124 Error:  124.542889451629\n",
      "Epoch:  2 Loss:  165.61919505944414 Error:  124.52431170700976\n",
      "Epoch:  3 Loss:  160.0839501713099 Error:  124.52016317852762\n",
      "Epoch:  4 Loss:  155.1753330016404 Error:  124.51954662155235\n",
      "Epoch:  5 Loss:  150.85925352975224 Error:  124.51917944789938\n",
      "Epoch:  6 Loss:  147.25156672617024 Error:  124.51887961317983\n",
      "Epoch:  7 Loss:  144.3815607220939 Error:  124.51884802455983\n",
      "Epoch:  8 Loss:  142.1833414977856 Error:  124.51897057120719\n",
      "Epoch:  9 Loss:  140.50453101383167 Error:  124.51928312071924\n",
      "Epoch:  10 Loss:  139.2102009205336 Error:  124.51957532771853\n",
      "Test error MAE:  0.19186351034376356\n",
      "Epoch:  1 Loss:  138.3851363042767 Error:  124.51982924978385\n",
      "Epoch:  2 Loss:  137.45187559020653 Error:  124.51939232203733\n",
      "Epoch:  3 Loss:  136.67403553309066 Error:  124.51878361772286\n",
      "Epoch:  4 Loss:  135.99990653455927 Error:  124.51852984232514\n",
      "Epoch:  5 Loss:  135.3539852024464 Error:  124.51895579385959\n",
      "Epoch:  6 Loss:  134.75447117344717 Error:  124.5187951022487\n",
      "Epoch:  7 Loss:  134.19219408678205 Error:  124.5188094524855\n",
      "Epoch:  8 Loss:  133.65991776712823 Error:  124.5187493950296\n",
      "Epoch:  9 Loss:  133.16502442520655 Error:  124.51910139586818\n",
      "Epoch:  10 Loss:  132.67192307482944 Error:  124.51879712252804\n",
      "Test error MAE:  0.18806390066941578\n",
      "Epoch:  1 Loss:  8.120858997768826 Error:  0.1323955292503039\n",
      "Epoch:  2 Loss:  7.564455016454061 Error:  0.13234242465760973\n",
      "Epoch:  3 Loss:  7.040776692496406 Error:  0.13230517705281575\n",
      "Epoch:  4 Loss:  6.542229525248209 Error:  0.132449750850598\n",
      "Epoch:  5 Loss:  6.120543766021728 Error:  0.13264360452691715\n",
      "Epoch:  6 Loss:  5.702603109677633 Error:  0.13273877857459915\n",
      "Epoch:  7 Loss:  5.3411602550082735 Error:  0.13249475955963136\n",
      "Epoch:  8 Loss:  4.942861019240485 Error:  0.13281019247240491\n",
      "Epoch:  9 Loss:  4.6642540587319266 Error:  0.13288736583458052\n",
      "Epoch:  10 Loss:  4.375224081675212 Error:  0.13308588845862282\n",
      "Test error MAE:  381.3108890293674\n",
      "[0.19186351034376356, 0.18806390066941578, 381.3108890293674]\n",
      "Validation loss: 127.23027214679352\n",
      "Training with hyperparams: {'hidden_dim': 512, 'lmbda': 1000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  135.37054809559598 Error:  124.54525188616152\n",
      "Epoch:  2 Loss:  128.8874528917034 Error:  124.52852734538277\n",
      "Epoch:  3 Loss:  128.5127586461185 Error:  124.5233517424779\n",
      "Epoch:  4 Loss:  128.1846077120706 Error:  124.52154418817732\n",
      "Epoch:  5 Loss:  127.88192860464032 Error:  124.5203676119949\n",
      "Epoch:  6 Loss:  127.60195224740532 Error:  124.51961047646034\n",
      "Epoch:  7 Loss:  127.34219615646963 Error:  124.51864014858945\n",
      "Epoch:  8 Loss:  127.10755260071058 Error:  124.51847454805052\n",
      "Epoch:  9 Loss:  126.89832095081887 Error:  124.51874886829866\n",
      "Epoch:  10 Loss:  126.71438101436316 Error:  124.51825684401092\n",
      "Test error MAE:  0.18932506210274166\n",
      "Epoch:  1 Loss:  126.56697239634696 Error:  124.51827447325661\n",
      "Epoch:  2 Loss:  126.42689978272728 Error:  124.5180185911863\n",
      "Epoch:  3 Loss:  126.30748203765141 Error:  124.51804091546977\n",
      "Epoch:  4 Loss:  126.20500184578842 Error:  124.51773101434614\n",
      "Epoch:  5 Loss:  126.1186759324556 Error:  124.51797845156005\n",
      "Epoch:  6 Loss:  126.04339410883657 Error:  124.51787429403389\n",
      "Epoch:  7 Loss:  125.97826467739063 Error:  124.51758002247034\n",
      "Epoch:  8 Loss:  125.92043346233582 Error:  124.51761836022808\n",
      "Epoch:  9 Loss:  125.86852938539526 Error:  124.5175909258509\n",
      "Epoch:  10 Loss:  125.8205976044194 Error:  124.51737354084682\n",
      "Test error MAE:  0.18736031419701046\n",
      "Epoch:  1 Loss:  1.4271428253915575 Error:  0.13186863155828582\n",
      "Epoch:  2 Loss:  1.3806918203830718 Error:  0.13168113521403738\n",
      "Epoch:  3 Loss:  1.3371171560552386 Error:  0.13151275830136405\n",
      "Epoch:  4 Loss:  1.2965918554200067 Error:  0.13153018462989066\n",
      "Epoch:  5 Loss:  1.2569299909803602 Error:  0.13117171145147746\n",
      "Epoch:  6 Loss:  1.2203278991911146 Error:  0.13118137957321274\n",
      "Epoch:  7 Loss:  1.1839922772513496 Error:  0.13111239878667724\n",
      "Epoch:  8 Loss:  1.1487456023693086 Error:  0.13126988261938094\n",
      "Epoch:  9 Loss:  1.1143844015068478 Error:  0.13123223591181968\n",
      "Epoch:  10 Loss:  1.0802698923481835 Error:  0.1311915945675638\n",
      "Test error MAE:  381.30759975754404\n",
      "[0.18932506210274166, 0.18736031419701046, 381.30759975754404]\n",
      "Validation loss: 127.22809504461459\n",
      "Training with hyperparams: {'hidden_dim': 512, 'lmbda': 1000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  132.81898265474297 Error:  124.53987121431345\n",
      "Epoch:  2 Loss:  128.44277745954108 Error:  124.5253453058808\n",
      "Epoch:  3 Loss:  127.85288385059057 Error:  124.52251593416996\n",
      "Epoch:  4 Loss:  127.38870312926474 Error:  124.520990630549\n",
      "Epoch:  5 Loss:  127.0327442522799 Error:  124.52045679377036\n",
      "Epoch:  6 Loss:  126.7567431029309 Error:  124.52023743679014\n",
      "Epoch:  7 Loss:  126.53835331322102 Error:  124.52085891139976\n",
      "Epoch:  8 Loss:  126.35422890507773 Error:  124.52080130794745\n",
      "Epoch:  9 Loss:  126.20181294773401 Error:  124.5209502654799\n",
      "Epoch:  10 Loss:  126.07162582740355 Error:  124.52060936458325\n",
      "Test error MAE:  0.19296983712249333\n",
      "Epoch:  1 Loss:  125.99328012680739 Error:  124.52067006730967\n",
      "Epoch:  2 Loss:  125.88580666365249 Error:  124.5212168603968\n",
      "Epoch:  3 Loss:  125.79914143915927 Error:  124.52093828025829\n",
      "Epoch:  4 Loss:  125.72243888860338 Error:  124.52049222437853\n",
      "Epoch:  5 Loss:  125.65394108148104 Error:  124.52041148905003\n",
      "Epoch:  6 Loss:  125.59302988882816 Error:  124.5205866133564\n",
      "Epoch:  7 Loss:  125.53545757893765 Error:  124.52031205854054\n",
      "Epoch:  8 Loss:  125.48253607950853 Error:  124.5202013779055\n",
      "Epoch:  9 Loss:  125.43087766143714 Error:  124.51967072712907\n",
      "Epoch:  10 Loss:  125.38098026594419 Error:  124.51953935941283\n",
      "Test error MAE:  0.18982134461402894\n",
      "Epoch:  1 Loss:  0.9770339813497332 Error:  0.1331667853726281\n",
      "Epoch:  2 Loss:  0.9272255056434208 Error:  0.13299883057673773\n",
      "Epoch:  3 Loss:  0.8763217071692149 Error:  0.13254859306746059\n",
      "Epoch:  4 Loss:  0.8307702210214403 Error:  0.13230488499005635\n",
      "Epoch:  5 Loss:  0.786493307352066 Error:  0.13218873308764564\n",
      "Epoch:  6 Loss:  0.7443646649519603 Error:  0.1319524408214622\n",
      "Epoch:  7 Loss:  0.7095544868045383 Error:  0.1320538361867269\n",
      "Epoch:  8 Loss:  0.679324992497762 Error:  0.13206759260760415\n",
      "Epoch:  9 Loss:  0.6473761585023668 Error:  0.13222775840097004\n",
      "Epoch:  10 Loss:  0.6185248805416955 Error:  0.13187933936715127\n",
      "Test error MAE:  381.3114643821662\n",
      "[0.19296983712249333, 0.18982134461402894, 381.3114643821662]\n",
      "Validation loss: 127.23141852130091\n",
      "Training with hyperparams: {'hidden_dim': 512, 'lmbda': 5000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  182.1996342305387 Error:  124.54610155799081\n",
      "Epoch:  2 Loss:  147.27320771806694 Error:  124.5283375409212\n",
      "Epoch:  3 Loss:  145.5057294502687 Error:  124.52264082331335\n",
      "Epoch:  4 Loss:  143.89074275198948 Error:  124.52026486061932\n",
      "Epoch:  5 Loss:  142.31382718246974 Error:  124.51906757651085\n",
      "Epoch:  6 Loss:  140.801288669029 Error:  124.51879702952135\n",
      "Epoch:  7 Loss:  139.3794513445222 Error:  124.51812629736541\n",
      "Epoch:  8 Loss:  138.06632060147405 Error:  124.51798860670141\n",
      "Epoch:  9 Loss:  136.8741672923056 Error:  124.51777300146523\n",
      "Epoch:  10 Loss:  135.81184332022505 Error:  124.51781960375858\n",
      "Test error MAE:  0.18975470728344387\n",
      "Epoch:  1 Loss:  134.93339313549941 Error:  124.51845593842563\n",
      "Epoch:  2 Loss:  134.12137998623794 Error:  124.51807061239575\n",
      "Epoch:  3 Loss:  133.4415332708466 Error:  124.51818261521586\n",
      "Epoch:  4 Loss:  132.8759359188294 Error:  124.51794718632873\n",
      "Epoch:  5 Loss:  132.40658786323633 Error:  124.51780985705973\n",
      "Epoch:  6 Loss:  132.00777317432875 Error:  124.51791547422998\n",
      "Epoch:  7 Loss:  131.66734523987503 Error:  124.51752954863765\n",
      "Epoch:  8 Loss:  131.35845348272431 Error:  124.51722308558024\n",
      "Epoch:  9 Loss:  131.09726903143894 Error:  124.51743035026816\n",
      "Epoch:  10 Loss:  130.85640851031528 Error:  124.51715412082967\n",
      "Test error MAE:  0.18807118833065034\n",
      "Epoch:  1 Loss:  6.410718602604336 Error:  0.13131785359647538\n",
      "Epoch:  2 Loss:  6.186244297027588 Error:  0.13131277933716773\n",
      "Epoch:  3 Loss:  5.965844533178541 Error:  0.1313043042189545\n",
      "Epoch:  4 Loss:  5.760755258136325 Error:  0.13137709001700085\n",
      "Epoch:  5 Loss:  5.566708093219333 Error:  0.13129021525382994\n",
      "Epoch:  6 Loss:  5.377516036563449 Error:  0.13119215236769782\n",
      "Epoch:  7 Loss:  5.197126833597819 Error:  0.13132346065507994\n",
      "Epoch:  8 Loss:  5.019644271002876 Error:  0.1312028536366092\n",
      "Epoch:  9 Loss:  4.84708846145206 Error:  0.13114578798413276\n",
      "Epoch:  10 Loss:  4.676696316401164 Error:  0.13167403091986973\n",
      "Test error MAE:  381.30926995961505\n",
      "[0.18975470728344387, 0.18807118833065034, 381.30926995961505]\n",
      "Validation loss: 127.22903195174304\n",
      "Training with hyperparams: {'hidden_dim': 512, 'lmbda': 5000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  165.56729783904686 Error:  124.54014606413881\n",
      "Epoch:  2 Loss:  144.37576053919418 Error:  124.5258810542775\n",
      "Epoch:  3 Loss:  141.55222393421644 Error:  124.52367589045107\n",
      "Epoch:  4 Loss:  139.21580329637848 Error:  124.52265004955986\n",
      "Epoch:  5 Loss:  137.26820027426388 Error:  124.52216018384762\n",
      "Epoch:  6 Loss:  135.6422884651784 Error:  124.52228563714229\n",
      "Epoch:  7 Loss:  134.3201501181956 Error:  124.52289672681455\n",
      "Epoch:  8 Loss:  133.30331073718125 Error:  124.52330479302098\n",
      "Epoch:  9 Loss:  132.51486616456106 Error:  124.5227560797769\n",
      "Epoch:  10 Loss:  131.90799644555938 Error:  124.52233877560396\n",
      "Test error MAE:  0.19603438410494062\n",
      "Epoch:  1 Loss:  131.4937390316738 Error:  124.52284884528163\n",
      "Epoch:  2 Loss:  131.0378019407894 Error:  124.52302728501263\n",
      "Epoch:  3 Loss:  130.66557810815533 Error:  124.52288444532772\n",
      "Epoch:  4 Loss:  130.31535769580455 Error:  124.52284004145794\n",
      "Epoch:  5 Loss:  129.99608310688748 Error:  124.52288818878404\n",
      "Epoch:  6 Loss:  129.704252358233 Error:  124.52203713441163\n",
      "Epoch:  7 Loss:  129.41943321870954 Error:  124.52186435620102\n",
      "Epoch:  8 Loss:  129.14252013302922 Error:  124.52165642506286\n",
      "Epoch:  9 Loss:  128.898141226072 Error:  124.52209548685659\n",
      "Epoch:  10 Loss:  128.65881756182466 Error:  124.5221187633075\n",
      "Test error MAE:  0.1929715116818746\n",
      "Epoch:  1 Loss:  4.200312383969625 Error:  0.1359190012017886\n",
      "Epoch:  2 Loss:  3.937315331565009 Error:  0.1362022776570585\n",
      "Epoch:  3 Loss:  3.6980933401319716 Error:  0.13593911147779889\n",
      "Epoch:  4 Loss:  3.4689442290200128 Error:  0.13600394659572176\n",
      "Epoch:  5 Loss:  3.2486467123031617 Error:  0.13591370946831174\n",
      "Epoch:  6 Loss:  3.0343936867184107 Error:  0.1360751239789857\n",
      "Epoch:  7 Loss:  2.839558153682285 Error:  0.13597922250628472\n",
      "Epoch:  8 Loss:  2.681704264216953 Error:  0.13597427151269384\n",
      "Epoch:  9 Loss:  2.524809679720137 Error:  0.13659778734048209\n",
      "Epoch:  10 Loss:  2.3803179330295987 Error:  0.13686691116955546\n",
      "Test error MAE:  381.3170332437889\n",
      "[0.19603438410494062, 0.1929715116818746, 381.3170332437889]\n",
      "Validation loss: 127.23534637985857\n",
      "Training with hyperparams: {'hidden_dim': 512, 'lmbda': 10000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  235.42805305223786 Error:  124.54639968619253\n",
      "Epoch:  2 Loss:  168.15508289551468 Error:  124.53075102616226\n",
      "Epoch:  3 Loss:  164.39696997738957 Error:  124.52558001783791\n",
      "Epoch:  4 Loss:  161.04454016953372 Error:  124.52386116646649\n",
      "Epoch:  5 Loss:  157.9122353671642 Error:  124.52291954919863\n",
      "Epoch:  6 Loss:  154.94184543309586 Error:  124.52210824752457\n",
      "Epoch:  7 Loss:  152.19273220019394 Error:  124.52177642394652\n",
      "Epoch:  8 Loss:  149.70236169622186 Error:  124.52146502960933\n",
      "Epoch:  9 Loss:  147.50321433249485 Error:  124.52117736620849\n",
      "Epoch:  10 Loss:  145.6016827701183 Error:  124.52085773554745\n",
      "Test error MAE:  0.19477121664418115\n",
      "Epoch:  1 Loss:  144.11752142531148 Error:  124.5214503021555\n",
      "Epoch:  2 Loss:  142.73063174258456 Error:  124.52143838683541\n",
      "Epoch:  3 Loss:  141.5721444012074 Error:  124.52119673847147\n",
      "Epoch:  4 Loss:  140.59917293505723 Error:  124.52127003133967\n",
      "Epoch:  5 Loss:  139.79523020112111 Error:  124.52137504543147\n",
      "Epoch:  6 Loss:  139.10700292265818 Error:  124.52083865519654\n",
      "Epoch:  7 Loss:  138.4914085516769 Error:  124.52097802366434\n",
      "Epoch:  8 Loss:  137.9436152918955 Error:  124.52116990650303\n",
      "Epoch:  9 Loss:  137.44504231013607 Error:  124.52121096229955\n",
      "Epoch:  10 Loss:  136.98344949657996 Error:  124.5210712222236\n",
      "Test error MAE:  0.19275695482889812\n",
      "Epoch:  1 Loss:  12.47490340338813 Error:  0.13499364000227715\n",
      "Epoch:  2 Loss:  12.00507508913676 Error:  0.13481998783018853\n",
      "Epoch:  3 Loss:  11.571557903289795 Error:  0.13477457587917646\n",
      "Epoch:  4 Loss:  11.16689993540446 Error:  0.1347709770831797\n",
      "Epoch:  5 Loss:  10.779095448387993 Error:  0.1347830630838871\n",
      "Epoch:  6 Loss:  10.413369099299112 Error:  0.13477490080727472\n",
      "Epoch:  7 Loss:  10.050881650712755 Error:  0.13476525396108627\n",
      "Epoch:  8 Loss:  9.703016069200304 Error:  0.13480205519331825\n",
      "Epoch:  9 Loss:  9.363631645838419 Error:  0.13489061974816852\n",
      "Epoch:  10 Loss:  9.029015318552654 Error:  0.13520299088623788\n",
      "Test error MAE:  381.31421782550484\n",
      "[0.19477121664418115, 0.19275695482889812, 381.31421782550484]\n",
      "Validation loss: 127.23391533232598\n",
      "Training with hyperparams: {'hidden_dim': 512, 'lmbda': 10000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  211.1504617326715 Error:  124.53854607999995\n",
      "Epoch:  2 Loss:  164.33432077557853 Error:  124.52143443869741\n",
      "Epoch:  3 Loss:  158.32698815592218 Error:  124.51824372738935\n",
      "Epoch:  4 Loss:  153.56636353824916 Error:  124.51719641183199\n",
      "Epoch:  5 Loss:  149.83284298757488 Error:  124.51701442512234\n",
      "Epoch:  6 Loss:  146.8628489140714 Error:  124.51648214978448\n",
      "Epoch:  7 Loss:  144.4831979194384 Error:  124.51662373835786\n",
      "Epoch:  8 Loss:  142.5744221398 Error:  124.51702735899539\n",
      "Epoch:  9 Loss:  141.01790795701274 Error:  124.51766448400998\n",
      "Epoch:  10 Loss:  139.7213005644552 Error:  124.51825751305631\n",
      "Test error MAE:  0.18941354751586914\n",
      "Epoch:  1 Loss:  138.8836031710164 Error:  124.51869819756973\n",
      "Epoch:  2 Loss:  137.78312527731563 Error:  124.51844170321239\n",
      "Epoch:  3 Loss:  136.9183638283376 Error:  124.5185113348318\n",
      "Epoch:  4 Loss:  136.13984118686633 Error:  124.51891702304731\n",
      "Epoch:  5 Loss:  135.4217114930742 Error:  124.51906667750204\n",
      "Epoch:  6 Loss:  134.77993430448382 Error:  124.519044007227\n",
      "Epoch:  7 Loss:  134.18851744726803 Error:  124.51942067358935\n",
      "Epoch:  8 Loss:  133.64517378539182 Error:  124.51950424005476\n",
      "Epoch:  9 Loss:  133.1021105948459 Error:  124.51942364134815\n",
      "Epoch:  10 Loss:  132.6197383001949 Error:  124.51952293029662\n",
      "Test error MAE:  0.18950939112239415\n",
      "Epoch:  1 Loss:  8.109128459294636 Error:  0.1332632056540913\n",
      "Epoch:  2 Loss:  7.582564714219835 Error:  0.13277568535672293\n",
      "Epoch:  3 Loss:  7.088173092736138 Error:  0.13292573897375\n",
      "Epoch:  4 Loss:  6.596445634629991 Error:  0.13282471978002125\n",
      "Epoch:  5 Loss:  6.174613979127672 Error:  0.1326744846171803\n",
      "Epoch:  6 Loss:  5.7502627770106 Error:  0.1325352949400743\n",
      "Epoch:  7 Loss:  5.401504267586602 Error:  0.13238225744830237\n",
      "Epoch:  8 Loss:  5.07246142493354 Error:  0.13236573222610687\n",
      "Epoch:  9 Loss:  4.728817637761434 Error:  0.13245154859291183\n",
      "Epoch:  10 Loss:  4.488547534412808 Error:  0.13258592759569485\n",
      "Test error MAE:  381.311696540903\n",
      "[0.18941354751586914, 0.18950939112239415, 381.311696540903]\n",
      "Validation loss: 127.2302064931804\n",
      "Training with hyperparams: {'hidden_dim': 1024, 'lmbda': 1000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  135.26529682888074 Error:  124.54406485003366\n",
      "Epoch:  2 Loss:  128.8105808938487 Error:  124.52888372431646\n",
      "Epoch:  3 Loss:  128.39837103211477 Error:  124.52492784432481\n",
      "Epoch:  4 Loss:  128.049386313792 Error:  124.5231806993317\n",
      "Epoch:  5 Loss:  127.74853825301267 Error:  124.52168723438562\n",
      "Epoch:  6 Loss:  127.48932780576556 Error:  124.52080740461524\n",
      "Epoch:  7 Loss:  127.25988866773884 Error:  124.52058050295945\n",
      "Epoch:  8 Loss:  127.05853618128916 Error:  124.51978970042775\n",
      "Epoch:  9 Loss:  126.87971119130596 Error:  124.51933142902811\n",
      "Epoch:  10 Loss:  126.72042418731732 Error:  124.51872863227062\n",
      "Test error MAE:  0.19003294375207688\n",
      "Epoch:  1 Loss:  126.59348767393091 Error:  124.51906522589454\n",
      "Epoch:  2 Loss:  126.46550025029129 Error:  124.51837443828248\n",
      "Epoch:  3 Loss:  126.35310870609926 Error:  124.51808257853047\n",
      "Epoch:  4 Loss:  126.25465392262748 Error:  124.51793343657523\n",
      "Epoch:  5 Loss:  126.16791177465674 Error:  124.51793100475595\n",
      "Epoch:  6 Loss:  126.09021762113893 Error:  124.51784564186347\n",
      "Epoch:  7 Loss:  126.02155914199486 Error:  124.51773352067123\n",
      "Epoch:  8 Loss:  125.95782679922125 Error:  124.51745215275984\n",
      "Epoch:  9 Loss:  125.90137505263425 Error:  124.51774132527997\n",
      "Epoch:  10 Loss:  125.84809935494755 Error:  124.51753451842606\n",
      "Test error MAE:  0.18804485036267174\n",
      "Epoch:  1 Loss:  1.4482914328575134 Error:  0.13144553775588672\n",
      "Epoch:  2 Loss:  1.3976974871423509 Error:  0.13137127823299832\n",
      "Epoch:  3 Loss:  1.3513362619611953 Error:  0.1312974854475922\n",
      "Epoch:  4 Loss:  1.3078080793221791 Error:  0.13120251670479774\n",
      "Epoch:  5 Loss:  1.2669430447949304 Error:  0.13120187893509866\n",
      "Epoch:  6 Loss:  1.227279798189799 Error:  0.1309094381829103\n",
      "Epoch:  7 Loss:  1.1898031367195978 Error:  0.13086702111694548\n",
      "Epoch:  8 Loss:  1.154143633445104 Error:  0.13083244512478512\n",
      "Epoch:  9 Loss:  1.1183087468147277 Error:  0.1307242042488522\n",
      "Epoch:  10 Loss:  1.084636159075631 Error:  0.13114676574865977\n",
      "Test error MAE:  381.3092051161961\n",
      "[0.19003294375207688, 0.18804485036267174, 381.3092051161961]\n",
      "Validation loss: 127.22909430343695\n",
      "Training with hyperparams: {'hidden_dim': 1024, 'lmbda': 1000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  132.47676580943417 Error:  124.53443967684936\n",
      "Epoch:  2 Loss:  128.41086360577788 Error:  124.5203021861864\n",
      "Epoch:  3 Loss:  127.85007605659828 Error:  124.51844825503531\n",
      "Epoch:  4 Loss:  127.39843746249595 Error:  124.51768562725086\n",
      "Epoch:  5 Loss:  127.03703709130876 Error:  124.51774545633391\n",
      "Epoch:  6 Loss:  126.74545348092411 Error:  124.5176072757733\n",
      "Epoch:  7 Loss:  126.50895700293981 Error:  124.5177622290977\n",
      "Epoch:  8 Loss:  126.31887024574065 Error:  124.51791005749047\n",
      "Epoch:  9 Loss:  126.16788112045674 Error:  124.51828659794639\n",
      "Epoch:  10 Loss:  126.04456749257076 Error:  124.51808026667392\n",
      "Test error MAE:  0.19235732820298937\n",
      "Epoch:  1 Loss:  125.95817815319876 Error:  124.51835897037488\n",
      "Epoch:  2 Loss:  125.86596534225379 Error:  124.51821199026\n",
      "Epoch:  3 Loss:  125.78685700089744 Error:  124.51834712185887\n",
      "Epoch:  4 Loss:  125.71639668405726 Error:  124.51797986834237\n",
      "Epoch:  5 Loss:  125.65433073378681 Error:  124.51797167864743\n",
      "Epoch:  6 Loss:  125.59357943025867 Error:  124.51772782256764\n",
      "Epoch:  7 Loss:  125.53729651081429 Error:  124.51785949458566\n",
      "Epoch:  8 Loss:  125.48374672083372 Error:  124.51759051422725\n",
      "Epoch:  9 Loss:  125.4344656521015 Error:  124.51720238661163\n",
      "Epoch:  10 Loss:  125.38536205988252 Error:  124.51720175431686\n",
      "Test error MAE:  0.1887507461839252\n",
      "Epoch:  1 Loss:  0.9854455696211921 Error:  0.13130361412962277\n",
      "Epoch:  2 Loss:  0.9390592243936327 Error:  0.1311807686256038\n",
      "Epoch:  3 Loss:  0.890768536594179 Error:  0.1308957929412524\n",
      "Epoch:  4 Loss:  0.847985503408644 Error:  0.1306659373972151\n",
      "Epoch:  5 Loss:  0.8006726582845052 Error:  0.13053425956103537\n",
      "Epoch:  6 Loss:  0.763680546813541 Error:  0.13041876206795375\n",
      "Epoch:  7 Loss:  0.7241797109444936 Error:  0.1306373196343581\n",
      "Epoch:  8 Loss:  0.6861061765087976 Error:  0.1303663111395306\n",
      "Epoch:  9 Loss:  0.6531561407777998 Error:  0.13040331850449244\n",
      "Epoch:  10 Loss:  0.629919206433826 Error:  0.13035820076862972\n",
      "Test error MAE:  381.30842894417316\n",
      "[0.19235732820298937, 0.1887507461839252, 381.30842894417316]\n",
      "Validation loss: 127.22984567285336\n",
      "Training with hyperparams: {'hidden_dim': 1024, 'lmbda': 5000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  180.33403315169087 Error:  124.54334738641307\n",
      "Epoch:  2 Loss:  146.19882716489641 Error:  124.52816270099262\n",
      "Epoch:  3 Loss:  144.38555704609732 Error:  124.52379730896334\n",
      "Epoch:  4 Loss:  142.7348165512085 Error:  124.52210266837913\n",
      "Epoch:  5 Loss:  141.1984502706635 Error:  124.5210912473751\n",
      "Epoch:  6 Loss:  139.7827367568284 Error:  124.51999751336119\n",
      "Epoch:  7 Loss:  138.49160299408302 Error:  124.52009743879016\n",
      "Epoch:  8 Loss:  137.32541985458204 Error:  124.52000124936693\n",
      "Epoch:  9 Loss:  136.28308481580757 Error:  124.51994675230443\n",
      "Epoch:  10 Loss:  135.37396832798305 Error:  124.52018178974309\n",
      "Test error MAE:  0.1925007051891751\n",
      "Epoch:  1 Loss:  134.6498543814327 Error:  124.51994555753268\n",
      "Epoch:  2 Loss:  133.94724932681308 Error:  124.51978774209705\n",
      "Epoch:  3 Loss:  133.34345463420567 Error:  124.51987842520636\n",
      "Epoch:  4 Loss:  132.8235530960426 Error:  124.51914489386456\n",
      "Epoch:  5 Loss:  132.37177362334862 Error:  124.51922002518445\n",
      "Epoch:  6 Loss:  131.98540633983828 Error:  124.51946667925026\n",
      "Epoch:  7 Loss:  131.64953095189642 Error:  124.51959317010105\n",
      "Epoch:  8 Loss:  131.3531459476171 Error:  124.51925264918403\n",
      "Epoch:  9 Loss:  131.084765321753 Error:  124.51900733680873\n",
      "Epoch:  10 Loss:  130.842238013664 Error:  124.51888100308983\n",
      "Test error MAE:  0.18975527783234913\n",
      "Epoch:  1 Loss:  6.381405446264479 Error:  0.13299838619099724\n",
      "Epoch:  2 Loss:  6.156758602460226 Error:  0.1327875554561615\n",
      "Epoch:  3 Loss:  5.936133201917013 Error:  0.1329735218650765\n",
      "Epoch:  4 Loss:  5.73342994319068 Error:  0.1328125949535105\n",
      "Epoch:  5 Loss:  5.542935670746697 Error:  0.132972970770465\n",
      "Epoch:  6 Loss:  5.355744904941982 Error:  0.13321218598220083\n",
      "Epoch:  7 Loss:  5.174825127919515 Error:  0.13313480234808392\n",
      "Epoch:  8 Loss:  5.001796129014757 Error:  0.133143533517917\n",
      "Epoch:  9 Loss:  4.83235682381524 Error:  0.1334476962685585\n",
      "Epoch:  10 Loss:  4.666167028745016 Error:  0.13347177331646284\n",
      "Test error MAE:  381.31329434365034\n",
      "[0.1925007051891751, 0.18975527783234913, 381.31329434365034]\n",
      "Validation loss: 127.23185010889063\n",
      "Training with hyperparams: {'hidden_dim': 1024, 'lmbda': 5000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  165.61284129539231 Error:  124.53778988081083\n",
      "Epoch:  2 Loss:  144.67463520135772 Error:  124.52523879564545\n",
      "Epoch:  3 Loss:  141.93381364158031 Error:  124.52300200234639\n",
      "Epoch:  4 Loss:  139.49102868926659 Error:  124.52206854982657\n",
      "Epoch:  5 Loss:  137.3696044750428 Error:  124.5211512566115\n",
      "Epoch:  6 Loss:  135.6300515378459 Error:  124.52113133710756\n",
      "Epoch:  7 Loss:  134.26313101843502 Error:  124.52120530002573\n",
      "Epoch:  8 Loss:  133.22314087192663 Error:  124.52152062048403\n",
      "Epoch:  9 Loss:  132.44141931212351 Error:  124.52177655253183\n",
      "Epoch:  10 Loss:  131.8447674365526 Error:  124.52176110789682\n",
      "Test error MAE:  0.19558057685693106\n",
      "Epoch:  1 Loss:  131.45427798689082 Error:  124.52213922821069\n",
      "Epoch:  2 Loss:  131.01629952634318 Error:  124.52184143252252\n",
      "Epoch:  3 Loss:  130.65912678536404 Error:  124.52205705718043\n",
      "Epoch:  4 Loss:  130.32113934099004 Error:  124.52242044744531\n",
      "Epoch:  5 Loss:  130.00892896866532 Error:  124.5220932726947\n",
      "Epoch:  6 Loss:  129.7075996184617 Error:  124.5223196873839\n",
      "Epoch:  7 Loss:  129.41939816046298 Error:  124.52290591647785\n",
      "Epoch:  8 Loss:  129.15212524874826 Error:  124.52226797516427\n",
      "Epoch:  9 Loss:  128.8842053091928 Error:  124.52186580387394\n",
      "Epoch:  10 Loss:  128.63261035319124 Error:  124.52195125734538\n",
      "Test error MAE:  0.1927333715889189\n",
      "Epoch:  1 Loss:  4.154398332701789 Error:  0.13602247519625557\n",
      "Epoch:  2 Loss:  3.894482175509135 Error:  0.13606455648938814\n",
      "Epoch:  3 Loss:  3.640496431456672 Error:  0.13613312914967537\n",
      "Epoch:  4 Loss:  3.415625336435106 Error:  0.1360342883401447\n",
      "Epoch:  5 Loss:  3.204565411143833 Error:  0.13598730663458505\n",
      "Epoch:  6 Loss:  2.9887865834765965 Error:  0.13606548913651043\n",
      "Epoch:  7 Loss:  2.794654725657569 Error:  0.13593448574344316\n",
      "Epoch:  8 Loss:  2.6285758905940586 Error:  0.13583769790000386\n",
      "Epoch:  9 Loss:  2.4742823958396913 Error:  0.13592022127575346\n",
      "Epoch:  10 Loss:  2.3113660004403855 Error:  0.13592879399657248\n",
      "Test error MAE:  381.3159622373906\n",
      "[0.19558057685693106, 0.1927333715889189, 381.3159622373906]\n",
      "Validation loss: 127.23475872861214\n",
      "Training with hyperparams: {'hidden_dim': 1024, 'lmbda': 10000, 'lr': 0.0001}\n",
      "Epoch:  1 Loss:  236.51876222417596 Error:  124.54241726053564\n",
      "Epoch:  2 Loss:  167.84904085652212 Error:  124.52697928902808\n",
      "Epoch:  3 Loss:  163.82670586832452 Error:  124.52288333736779\n",
      "Epoch:  4 Loss:  160.2508189812135 Error:  124.52100617798527\n",
      "Epoch:  5 Loss:  157.04400051845593 Error:  124.52023479317346\n",
      "Epoch:  6 Loss:  154.22424052806383 Error:  124.51997477854236\n",
      "Epoch:  7 Loss:  151.74458124396506 Error:  124.5192652462741\n",
      "Epoch:  8 Loss:  149.58945947282768 Error:  124.51965673502242\n",
      "Epoch:  9 Loss:  147.7066199806299 Error:  124.51928744732999\n",
      "Epoch:  10 Loss:  146.06569438034228 Error:  124.51890593315109\n",
      "Test error MAE:  0.19200778073734706\n",
      "Epoch:  1 Loss:  144.78542240014238 Error:  124.5189020828752\n",
      "Epoch:  2 Loss:  143.47848437877184 Error:  124.51883032189662\n",
      "Epoch:  3 Loss:  142.33867190928942 Error:  124.51866066899527\n",
      "Epoch:  4 Loss:  141.3344702667065 Error:  124.51858990162276\n",
      "Epoch:  5 Loss:  140.44728781667988 Error:  124.51825920115697\n",
      "Epoch:  6 Loss:  139.65812115187055 Error:  124.51829919478531\n",
      "Epoch:  7 Loss:  138.94091865453828 Error:  124.51870932044943\n",
      "Epoch:  8 Loss:  138.30192178018976 Error:  124.51826658694262\n",
      "Epoch:  9 Loss:  137.7234284690257 Error:  124.51862978374355\n",
      "Epoch:  10 Loss:  137.21060597494747 Error:  124.51867639524548\n",
      "Test error MAE:  0.19078849090470207\n",
      "Epoch:  1 Loss:  12.65288971265157 Error:  0.13303113132715225\n",
      "Epoch:  2 Loss:  12.161789475546943 Error:  0.13288866115940942\n",
      "Epoch:  3 Loss:  11.702086718877156 Error:  0.13276722249057557\n",
      "Epoch:  4 Loss:  11.28323769569397 Error:  0.13314166102144454\n",
      "Epoch:  5 Loss:  10.878753635618422 Error:  0.13327483087778091\n",
      "Epoch:  6 Loss:  10.49791497124566 Error:  0.1334011326233546\n",
      "Epoch:  7 Loss:  10.131870407528348 Error:  0.1332715630531311\n",
      "Epoch:  8 Loss:  9.771808958053589 Error:  0.1330681249499321\n",
      "Epoch:  9 Loss:  9.431491809421116 Error:  0.13316589709785248\n",
      "Epoch:  10 Loss:  9.097101815541585 Error:  0.13336919554405743\n",
      "Test error MAE:  381.3125260242007\n",
      "[0.19200778073734706, 0.19078849090470207, 381.3125260242007]\n",
      "Validation loss: 127.23177409861425\n",
      "Training with hyperparams: {'hidden_dim': 1024, 'lmbda': 10000, 'lr': 0.0002}\n",
      "Epoch:  1 Loss:  204.79211567225082 Error:  124.53845071842831\n",
      "Epoch:  2 Loss:  164.04984701349494 Error:  124.52279211321239\n",
      "Epoch:  3 Loss:  158.78610662396034 Error:  124.52078737159458\n",
      "Epoch:  4 Loss:  154.06570085246912 Error:  124.52002279033486\n",
      "Epoch:  5 Loss:  150.0055911889237 Error:  124.51896903186702\n",
      "Epoch:  6 Loss:  146.63342842359222 Error:  124.51900055619438\n",
      "Epoch:  7 Loss:  143.96006451296003 Error:  124.51932346268316\n",
      "Epoch:  8 Loss:  141.90513752283675 Error:  124.51907824833741\n",
      "Epoch:  9 Loss:  140.34276100758757 Error:  124.51925803503293\n",
      "Epoch:  10 Loss:  139.13111367386378 Error:  124.51945620339907\n",
      "Test error MAE:  0.1915516432788637\n",
      "Epoch:  1 Loss:  138.35175833541356 Error:  124.51950641704744\n",
      "Epoch:  2 Loss:  137.45782343189367 Error:  124.52015596301703\n",
      "Epoch:  3 Loss:  136.6538082615713 Error:  124.5197808572583\n",
      "Epoch:  4 Loss:  135.9776904395457 Error:  124.51975578823117\n",
      "Epoch:  5 Loss:  135.3461155730687 Error:  124.51965616517857\n",
      "Epoch:  6 Loss:  134.74921395805444 Error:  124.51996701219109\n",
      "Epoch:  7 Loss:  134.19099686118994 Error:  124.51983911845457\n",
      "Epoch:  8 Loss:  133.66538004392987 Error:  124.5201846336046\n",
      "Epoch:  9 Loss:  133.15459489286616 Error:  124.52075919584277\n",
      "Epoch:  10 Loss:  132.68274019005594 Error:  124.52046722056491\n",
      "Test error MAE:  0.19088389343685574\n",
      "Epoch:  1 Loss:  8.081746763653225 Error:  0.13457614448335437\n",
      "Epoch:  2 Loss:  7.57216722700331 Error:  0.1339607895248466\n",
      "Epoch:  3 Loss:  7.075055662790934 Error:  0.13414538668261633\n",
      "Epoch:  4 Loss:  6.603181356853909 Error:  0.13481427588396602\n",
      "Epoch:  5 Loss:  6.180426216125488 Error:  0.13456126691566572\n",
      "Epoch:  6 Loss:  5.7327495892842615 Error:  0.13447316818767124\n",
      "Epoch:  7 Loss:  5.357218843036228 Error:  0.13490637929903138\n",
      "Epoch:  8 Loss:  5.007948120435079 Error:  0.1351158886320061\n",
      "Epoch:  9 Loss:  4.672629059685601 Error:  0.13538519243399302\n",
      "Epoch:  10 Loss:  4.41460870107015 Error:  0.135283073120647\n",
      "Test error MAE:  381.31341707503253\n",
      "[0.1915516432788637, 0.19088389343685574, 381.31341707503253]\n",
      "Validation loss: 127.23195087058275\n",
      "Best hyperparameters: {'hidden_dim': 256, 'lmbda': 1000, 'lr': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Define sets of hyperparameters for tuning\n",
    "learning_rates = [0.0001, 0.0002]\n",
    "lambdas = [1000, 5000, 10000]\n",
    "hidden_dims = [256, 512, 1024]\n",
    "\n",
    "num_splt = 3\n",
    "epochs = 10\n",
    "# lr = 0.00005\n",
    "# lmbda = 5000\n",
    "lr_dim = 160\n",
    "hr_dim = 320\n",
    "# hidden_dim = 512\n",
    "padding = 30\n",
    "ks = [0.7, 0.3]\n",
    "\n",
    "hyperparam_grid = {\n",
    "    'lr': learning_rates,\n",
    "    'lmbda': lambdas,\n",
    "    'hidden_dim': hidden_dims\n",
    "}\n",
    "\n",
    "best_hyperparams = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for hyperparams in ParameterGrid(hyperparam_grid):\n",
    "    print(f\"Training with hyperparams: {hyperparams}\")\n",
    "\n",
    "    args = argparse.Namespace(epochs=epochs,lmbda = hyperparams['lmbda'], lr_dim=lr_dim, hr_dim=hr_dim, hidden_dim = hyperparams['hidden_dim'], padding=padding)\n",
    "    \n",
    "    model = GSRNet(ks, args)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparams['lr'])\n",
    "    \n",
    "    cv_loss = []\n",
    "    for train_index, val_index in cv.split(lr_train):\n",
    "        lr_train_fold, lr_val_fold = lr_train[train_index], lr_train[val_index]\n",
    "        hr_train_fold, hr_val_fold = hr_train[train_index], hr_train[val_index]\n",
    "\n",
    "        train(model, optimizer, lr_train_fold, hr_train_fold, args)\n",
    "        val_loss = test(model, lr_val_fold, hr_val_fold, args)\n",
    "        cv_loss.append(val_loss)\n",
    "    print(cv_loss)\n",
    "    avg_val_loss = np.mean(cv_loss)\n",
    "    print(f\"Validation loss: {avg_val_loss}\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_hyperparams = hyperparams\n",
    "\n",
    "print(f\"Best hyperparameters: {best_hyperparams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  91.82829734460631 Error:  82.77363934323414\n",
      "Epoch:  2 Loss:  86.90207556112489 Error:  82.75784606230793\n",
      "Epoch:  3 Loss:  86.4174696972121 Error:  82.75415973726716\n",
      "Epoch:  4 Loss:  85.97195963005521 Error:  82.75309094703242\n",
      "Epoch:  5 Loss:  85.56911781296802 Error:  82.75169043415296\n",
      "Epoch:  6 Loss:  85.22096520662308 Error:  82.75080910575257\n",
      "Epoch:  7 Loss:  84.93222978221836 Error:  82.75081919711917\n",
      "Epoch:  8 Loss:  84.69876960587146 Error:  82.75068719963085\n",
      "Epoch:  9 Loss:  84.51116934374197 Error:  82.75057061289006\n",
      "Epoch:  10 Loss:  84.36385146094791 Error:  82.75011517190889\n",
      "Test error MAE:  0.18168841214740977\n"
     ]
    }
   ],
   "source": [
    "# run 'hidden_dim': 256, 'lmbda': 1000, 'lr': 0.0001 on test set\n",
    "args = argparse.Namespace(epochs=epochs,lmbda = best_hyperparams['lmbda'], lr_dim=lr_dim, hr_dim=hr_dim, hidden_dim = best_hyperparams['hidden_dim'], padding=padding)\n",
    "model = GSRNet(ks, args)\n",
    "# train on full training set\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_hyperparams['lr'])\n",
    "train(model, optimizer, lr_train, hr_train, args)\n",
    "# test on test set\n",
    "test_loss = test(model, lr_test, hr_test, args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
