{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "from model import *\n",
    "from train import test\n",
    "import torch.optim as optim\n",
    "\n",
    "from MatrixVectorizer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csvs as numpy\n",
    "lr_data_path = '../data/lr_train.csv'\n",
    "hr_data_path = '../data/hr_train.csv'\n",
    "\n",
    "lr_train_data = np.loadtxt(lr_data_path, delimiter=',')\n",
    "hr_train_data = np.loadtxt(hr_data_path, delimiter=',')\n",
    "lr_train_data[lr_train_data < 0] = 0\n",
    "np.nan_to_num(lr_train_data, copy=False)\n",
    "\n",
    "hr_train_data[hr_train_data < 0] = 0\n",
    "np.nan_to_num(hr_train_data, copy=False)\n",
    "\n",
    "# map the anti-vectorize function to each row of the lr_train_data\n",
    "\n",
    "lr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 160) for row in lr_train_data])\n",
    "hr_train_data_vectorized = np.array([MatrixVectorizer.anti_vectorize(row, 260) for row in hr_train_data])\n",
    "num_samples = hr_train_data_vectorized.shape[0]\n",
    "split = int(num_samples * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects_adj,subjects_labels = lr_train_data_vectorized[:split], hr_train_data_vectorized[:split]\n",
    "\n",
    "held_out_subjects_adj,held_out_subjects_labels = lr_train_data_vectorized[split:], hr_train_data_vectorized[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splt = 3\n",
    "epochs = 15\n",
    "lr = 0.001\n",
    "lmbda = 16\n",
    "lr_dim = 160\n",
    "hr_dim = 320\n",
    "hidden_dim = 320\n",
    "padding = 30\n",
    "dropout = 0\n",
    "args = argparse.Namespace()\n",
    "args.epochs = epochs\n",
    "args.lr = lr\n",
    "args.lmbda = lmbda\n",
    "args.lr_dim = lr_dim\n",
    "args.hr_dim = hr_dim\n",
    "args.hidden_dim = hidden_dim\n",
    "args.padding = padding\n",
    "args.p = dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks = [0]\n",
    "ks = [0.7, 0.3]\n",
    "model = GSRNet(ks, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "def train(model, optimizer, subjects_adj,subjects_labels, args): \n",
    "  #, subjects_adj_test, subjects_ground_truth_test):\n",
    "  \n",
    "  all_epochs_loss = []\n",
    "  no_epochs = args.epochs\n",
    "\n",
    "  for epoch in range(no_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_error = []\n",
    "\n",
    "    model.train()\n",
    "    for lr,hr in zip(subjects_adj,subjects_labels):      \n",
    "      lr = torch.from_numpy(lr).type(torch.FloatTensor)\n",
    "      hr = torch.from_numpy(hr).type(torch.FloatTensor)\n",
    "      \n",
    "      \n",
    "      # net_outs,start_gcn_outs,layer_outs = model(lr)\n",
    "      model_outputs,net_outs,start_gcn_outs,layer_outs = model(lr)\n",
    "      # model_outputs  = unpad(model_outputs, args.padding)\n",
    "      # weights = unpad(model.layer.weights, args.padding)\n",
    "      \n",
    "\n",
    "      padded_hr = pad_HR_adj(hr,args.padding)\n",
    "      eig_val_hr, U_hr = torch.linalg.eigh(padded_hr, UPLO='U')\n",
    "\n",
    "      # print the shapes of the outputs\n",
    "      # print(f\"{net_outs.shape} ; {start_gcn_outs.shape}\")\n",
    "      # print(f\"{model.layer.weights.shape} ; {U_hr.shape}\")\n",
    "      # print(f\"{model_outputs.shape} ; {hr.shape}\")\n",
    "      \n",
    "      # loss = criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + args.lmbda * criterion(model_outputs, hr) \n",
    "      # loss = criterion(model_outputs, hr) \n",
    "      loss = args.lmbda * criterion(net_outs, start_gcn_outs) + criterion(model.layer.weights,U_hr) + criterion(model_outputs, padded_hr) \n",
    "\n",
    "      \n",
    "      error = criterion(model_outputs, padded_hr)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss.append(loss.item())\n",
    "      epoch_error.append(error.item())\n",
    "      \n",
    "  \n",
    "    model.eval()\n",
    "    print(\"Epoch: \",epoch+1, \"Loss: \", np.mean(epoch_loss), \"Error: \", np.mean(epoch_error))\n",
    "    test(model, held_out_subjects_adj, held_out_subjects_labels, args)\n",
    "    # test(model, subjects_adj_test, subjects_ground_truth_test, args)\n",
    "    all_epochs_loss.append(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  82.89344727770606 Error:  82.75224178173204\n",
      "Epoch:  2 Loss:  82.82422540147803 Error:  82.73462091086071\n",
      "Epoch:  3 Loss:  82.81352242760694 Error:  82.73449453005372\n",
      "Epoch:  4 Loss:  82.80866831563301 Error:  82.73476081246983\n",
      "Epoch:  5 Loss:  82.80508683299395 Error:  82.7347744709409\n",
      "Epoch:  6 Loss:  82.80389080519107 Error:  82.73490901374772\n",
      "Epoch:  7 Loss:  82.80273461764428 Error:  82.7352214969917\n",
      "Epoch:  8 Loss:  82.80248434819393 Error:  82.73551215214738\n",
      "Epoch:  9 Loss:  82.80234912938592 Error:  82.73551061982984\n",
      "Epoch:  10 Loss:  82.80304316342321 Error:  82.73586775673859\n",
      "Epoch:  11 Loss:  82.80261548241573 Error:  82.7359223379684\n",
      "Epoch:  12 Loss:  82.80209098878636 Error:  82.73603570072063\n",
      "Epoch:  13 Loss:  82.80149550402342 Error:  82.73593152759236\n",
      "Epoch:  14 Loss:  82.80187646522006 Error:  82.73594717592445\n",
      "Epoch:  15 Loss:  82.80088280007911 Error:  82.73597702478517\n",
      "Held out test score:\n",
      "Test error MAE:  0.17638734991059585\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "train(model, optimizer, subjects_adj, subjects_labels, args)\n",
    "\n",
    "print('Held out test score:')\n",
    "test(model, held_out_subjects_adj, held_out_subjects_labels, args)\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(model)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# # optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "# for train_index, test_index in cv.split(subjects_adj):\n",
    "#     subjects_adj_train = subjects_adj[train_index]  # Get training data \n",
    "#     subjects_adj_test = subjects_adj[test_index]   # Get testing data \n",
    "#     subjects_ground_truth_train = subjects_labels[train_index]\n",
    "#     subjects_ground_truth_test = subjects_labels[test_index]\n",
    "\n",
    "#     train(model, optimizer, subjects_adj_train, subjects_ground_truth_train, args, subjects_adj_test, subjects_ground_truth_test)\n",
    "    \n",
    "#     print('Held out test score:')\n",
    "#     test(model, held_out_subjects_adj, held_out_subjects_labels, args)\n",
    "#     print('------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
